import pandas as pd
import sys
import os
from pathlib import Path
from urllib.parse import urlparse
import asyncio
import json
import ast


sys.path.append(Path(__file__).parent.as_posix())  # Ajoute le rÃ©pertoire parent au chemin de recherche
OUTPUT_DIR = Path(__file__).parent / "crawl_results"  # RÃ©pertoire de sortie pour les rÃ©sultats du crawl
OUTPUT_DIR.mkdir(exist_ok=True)  # CrÃ©e le rÃ©pertoire s'il n'existe pas

from main import main  # Importer la fonction main depuis le fichier main.py
from googleS import run_google_search  # importe la fonction de recherche Google
from gemini_markdown import gminimarkdown  # importe la fonction de recherche Gemini

DEFAULT_QUERY_LIST = ["arquiteto sao paulo", "architecte sao paulo"]

def get_unique_urls(query_list: list[str]) -> list[str]:
    """Launch Google searches and return a unique list of URLs."""

    all_urls: list[str] = []
    for query in query_list:
        print(f"ðŸ” Recherche Google pour : '{query}'")
        urls_for_query = run_google_search(query, lang="fr", region="br", num_results=3, advanced=False)
        all_urls.extend(urls_for_query)

    unique_urls = list(dict.fromkeys(all_urls))
    print(f"ðŸŒ Nombre total d'URLs : {len(unique_urls)}")
    return unique_urls



prompt_template = """
Vous Ãªtes un assistant spÃ©cialisÃ© dans l'extraction de contacts et de rÃ©seaux sociaux Ã  partir de contenu Markdown provenant d'un sites web.
Objectif : retourner un JSON structurÃ© avec les champs suivants :
- website : URL principale (domaine racine) du site analysÃ©.
- emails : liste des adresses email principales de contact trouvÃ©es.
- phone_numbers : liste des numÃ©ros de tÃ©lÃ©phone de contact.
- addresses : liste des adresses postales ou physiques identifiÃ©es.
- social_links : liste des URLs officielles du site pour ces plateformes ou services : LinkedIn, Instagram, Facebook, Twitter/X, YouTube, WhatsApp Web, API WhatsApp Business, et tout autre endpoint API officiel dÃ©tectÃ© (REST, GraphQL, etc.).

Contraintes :
- Uniquement les informations appartenant au site cible (pas de donnÃ©es de sites tiers).
- Ã‰liminer les doublons dans chaque champ.
- Si le site contient des liens vers des API publiques (ex : WhatsApp API, GraphQL, etc.), incluez-les dans social_links.

Exemple de structure JSON attendue :

{
    "website": "https://www.exemple.com",
    "emails": ["contact@exemple.com", "info@exemple.com"],
    "phone_numbers": ["+33 1 23 45 67 89"],
    "addresse": ["123 Rue Exemple, Paris, France"],
    "social_links": [
        "https://www.linkedin.com/company/exemple",
        "https://www.instagram.com/exemple",
        "https://www.facebook.com/exemple",
        "https://twitter.com/exemple",
        "https://www.youtube.com/c/exemple",
        "https://api.whatsapp.com/send?phone=123456789"
    ]
}
"""

async def run_batch(urls: list[str]) -> None:

    gemini_results = []

    for url in urls:
        print(f"\n=== Crawl : {url} ===")
        markdownd = await main(url)
        out_path = OUTPUT_DIR / f"{urlparse(url).netloc.replace('www.', '')}.md"
        out_path.write_text(markdownd or "")

        gmini_result = gminimarkdown(prompt_template, url, markdownd)
        output_json_path = OUTPUT_DIR / f"{urlparse(url).netloc.replace('www.', '')}-gmini-result.json"
        output_json_path.parent.mkdir(parents=True, exist_ok=True)
        output_json_path.write_text(gmini_result or "")
        print(f"â†’ RÃ©sultat Gemini enregistrÃ© dans {output_json_path}")

        gemini_results.append(gmini_result)
      

    clean_results = []

    for result in gemini_results:
        try:
            # Remove markdown formatting like ```json ... ```
            cleaned = result.strip()
            if cleaned.startswith("```json"):
                cleaned = cleaned[len("```json"):].strip()
            if cleaned.startswith("```"):
                cleaned = cleaned[len("```"):].strip()
            if cleaned.endswith("```"):
                cleaned = cleaned[:-3].strip()

            json_obj = json.loads(cleaned)
            clean_results.append(json_obj)
        except Exception as e:
            print(f"Erreur de parsing sur un rÃ©sultat Gemini : {e}")
            clean_results.append({"error": "Invalid JSON structure", "raw_result": result})

    final_output_path = OUTPUT_DIR / "gemini_results.json"
    final_output_path.write_text(json.dumps(clean_results, ensure_ascii=False, indent=2))
    print(f"â†’ Tous les rÃ©sultats Gemini rassemblÃ©s proprement dans {final_output_path}")

    # Export to Excel
    df = pd.json_normalize(clean_results)
    excel_output_path = OUTPUT_DIR / "gemini_results.xlsx"
    df.to_excel(excel_output_path, index=False)
    print(f"â†’ RÃ©sultats Gemini exportÃ©s dans {excel_output_path}")

    # Open the Excel file automatically (for MacOS)
    os.system(f"open '{excel_output_path}'")


async def run_xt(query_list: list[str] | None = None) -> None:
    """Entry point used by both CLI and webapp."""
    if query_list is None:
        query_list = DEFAULT_QUERY_LIST
    urls = get_unique_urls(query_list)
    await run_batch(urls)


if __name__ == "__main__":
    asyncio.run(run_xt())
